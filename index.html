<html>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <head>
    <title>Chaofeng</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_1155135_oq1ut3zz63j.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/fonts.css">
</head>

<body>
	<div class="main-container">
    <!-------------------------------  Introduction -------------------------------------------->
		<div class="content-container font-hei">
        <div class="hflex-container" id="profile">
				<img src="images/me.jpg">
				<div>
          <br>
					<b style="font-size:22px"><em>WU MENG</em></b>
					<b class="font-song" style="font-size:22px">(吴萌)</b>
					
					<table>
				        <tbody>
                  <tr>
                    <td>
                      Email: mwube@connect.ust.hk
                    </td>
                  </tr>
                  <tr>
                    <td><br></a></td>
                  </tr>
				        	<tr>
				        		<!-- <td width="60px"><b>Email</b></td> -->
				        		<td><i class="fa fa-envelope" style="color:black;font-size:22;"></i> chaofenghust [at] gmail.com</td>
				        	</tr>
					        <!-- <tr>
					        	<td style="vertical-align:text-top;"><b>Office</b></td>
					        	<td>CB411, Chow Yei Ching Building, <br>
					        		The University of Hong Kong,
									Pokfulam Road, Hong Kong</td> -->
							<!-- </tr> -->
							<tr>
								<td colspan="2">
									<br>
									<a href="https://github.com/chaofengc" target="_blank"><i class="fa fa-github" style="color:black;font-size:22;"></i>&nbsp;Github</a>
									<!-- <a href="https://www.zhihu.com/people/fly-cfchen/activities" target="_blank"><i class="iconfont icon-zhihu" style="color:black;"></i>&nbsp;Zhihu</a> -->
									<a href="files/resume-cfchen-en.pdf" target="_blank"><i class="iconfont icon-jianli" style="color:black;font-size:20;"></i>&nbsp;CV</a>
                  <a href="https://www.linkedin.com/in/%E9%99%88-%E8%B6%85%E9%94%8B-aa96518b/" target="_blank"><i class="fa fa-linkedin-square" style="color:black;font-size:22;"></i>&nbsp;LinkedIn</a>
                  <a href="https://scholar.google.com/citations?user=lxiqnI0AAAAJ&hl=en" target="_blank"><i class="iconfont icon-gscholar" style="color:black;font-size:20;"></i>&nbsp;Google Scholar</a>
								</td>
								</td>
							</tr>
				        </tbody>
		        	</table>
			    </div>
        </div>
		<!-- </div> -->
 <!--
    <!-------------------------------  About me -------------------------------------------->
		<!-- <div class="content-container"> -->
			<h2>About Me</h2>
			<p>I am currently a postdoctoral research fellow at S-Lab in Nanyang Technological University, working with <a href="https://personal.ntu.edu.sg/wslin/Home.html" target="_blank">Prof. Weisi Lin</a>. I received my Ph.D. degree from <a href="https://www.cs.hku.hk/" target="_blank">Dept. of Computer Science at the University of Hong Kong</a> in January 2021. I did my Ph.D. research at <a href="http://www.visionlab.cs.hku.hk/">Computer Vision Lab in HKU</a>, advised by <a href="http://i.cs.hku.hk/~kykwong/" target="_blank">Dr. Kenneth K.Y. Wong</a>. Prior to studying at HKU, I received my B.Eng. from <a href="http://www.hust.edu.cn" target="_blank">Huazhong University of Science and Technology</a>.</p>

			<p>My interests are centered around Computer Vision and Deep Learning. Current research topics include:</p>
          <ul>
            <li>Low level vision, including image quality assessment, restoration and enhancement.</li>
            <li>Image-to-image translation</li>
            <li>3D-aware image synthesis/rendering/editing</li>
            <li>Face related tasks</li>
					</ul>
    <!-- </div> -->
    <!-------------------------------  Education -------------------------------------------->
    <h2>News</h2>
    <div class="news">
    <ul class="news">
        
    </div>

    <!-------------------------------  Experience -------------------------------------------->
    <!-- <div class="content-container" display="flex"> -->
		<h2>Experience</h2>
      <div class="experience">
      <table>
        <tr>
          <td>Sep 2021 - Present</td>
          <td> </a></td>
        </tr>
        <tr>
          <td>Mar 2021 - Aug 2021</td>
          <td> /a></td>
        </tr>
        <tr>
          <td>Nov 2019 - Mar 2021</td>
          <td> ng Li</a> </td>
        </tr>
        <tr>
          <td>May 2019 - Oct 2019</td>
          <td> </a></td>
        </tr>
          <td>Jun 2018 - Mar 2019</td>
          <td> 
        <tr>
        </tr>
      </table>
    </div>
    <!-------------------------------  Publications -------------------------------------------->
    <!-- <div class="content-container"> -->
		<h2>Publications</h2>
        <h3>Conference Proceedings</h3> 
        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
         		  <img src="images/AAAI2023_MIMO.png">
            </td>
            <td>
              <p class="title">MIMO Is All You Need: A Strong Multi-In-Multi-Out Baseline for Video Prediction</p>
         		  <p class="authors">Shuliang Ning<sup>*</sup>, Mengcheng Lan<sup>*</sup>, Yanran Li, <span class="author_me">Chaofeng Chen</span>, Qian Chen, Xunlai Chen, Xiaoguang Han, Shuguang Cui</p>
              <p class="venue">Association for the Advancement of Artificial Intelligence (AAAI), 2023</p>
              <a href="https://arxiv.org/abs/2212.04655" target="_blank"><img class="imgbadge arxivbadge"></a>
            </td>
          </table>
        </div> 

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
         		  <img src="images/NIPS2022_nerfs3.gif">
            </td>
            <td>
              <p class="title">S<sup>3</sup>-NeRF: Neural Reflectance Field from Shading and Shadow under a Single Viewpoint</p>
         		  <p class="authors">Wenqi Yang, Guanying Chen, <span class="author_me">Chaofeng Chen</span>, Zhenfang Chen, Kwan-Yee K. Wong</p>
              <p  
            </td>
          </table>
        </div> 

        <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
         		    <img src="images/ECCV2022_fastvqa.gif">
              </td>
              <td>
                <p class="title">FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling</p>
         		    <p class="authors">Haoning Wu, <span class="author_me">Chaofeng Chen</span>, Jingwen Hou, Liang Liao, Annan Wang, Wenxiu Sun, Qiong Yan, Weisi Lin</p>
                <p class="venue">European Conference on Computer Vision (ECCV), 2022</p>
                <a href="https://arxiv.org/abs/2207.02595v1" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/TimothyHTimothy/FAST-VQA" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/TimothyHTimothy/FAST-VQA?style=social"></a>
              </td>
            </table>
        </div> 
        
        <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
         		    <img src="images/ECCV2022_ReDegNet.jpg">
              </td>
              <td>
                <p class="title">From Face to Natural Image: Learning Real Degradation for Blind Image Super-Resolution</p>
         		    <p class="authors">Xiaoming Li, <span class="author_me">Chaofeng Chen</span>, Xianhui Lin, Wangmeng Zuo, Lei Zhang</p>
                <p class="venue">European Conference on Computer Vision (ECCV), 2022</p>
                <a href="https://arxiv.org/abs/2210.00752" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/csxmli2016/ReDegNet" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/csxmli2016/ReDegNet?style=social"></a>
              </td>
            </table>
        </div> 

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
         		  <img src="images/eccv22_mvps2.gif">
            </td>
            <td>
              <p 
          </table>
        </div> 
        
        <div class="hflex-container" id="paper">
          <table>
            <td  
          </table>
        </div> 

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
         		  <img src="images/MM2022_TPQI.jpg">
            </td>
             <td>
              <p class="title">Exploring the Effectiveness of Video Perceptual Representation in Blind Video Quality Assessment</p>
         		  <p class="authors">Liang Liao, Kangmin Xu, Haoning Wu, <span class="author_me">Chaofeng Chen</span>, Wenxiu Sun, Qiong Yan, Weisi Lin</p>
              <p class="venue">ACM Multimedia, 2022 (<b style="color:red;">Oral Presentation</b>)</p>
              <a href="https://arxiv.org/abs/2207.03723" target="_blank"><img class="imgbadge arxivbadge"></a>
              <a href="https://github.com/UoLMM/TPQI-VQA" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/UoLMM/TPQI-VQA?style=social"></a>
             </td>
            </table>
        </div> 

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
         		  <img src="images/ICIP2022_ffrnet.jpg">
            </td>
             <td>
              <p class="title">A Unified Framework for Masked and Mask-Free Face Recognition via Feature Rectification</p>
         		  <p class="authors">Shaozhe Hao, <span class="author_me">Chaofeng Chen</span>, Zhenfang Chen, Kwan-Yee K. Wong</p>
              <p class="venue">ICIP, 2022</p>
              <a href="https://arxiv.org/abs/2202.07358" target="_blank"><img class="imgbadge arxivbadge"></a>
              <a href="https://github.com/haoosz/FFR-Net" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/haoosz/FFR-Net?style=social"></a>
             </td>
          </table>
        </div> 

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
            <img src="images/ICCV2021_HDRNet.jpg">
            </td>
            <td>
              <p class="title">HDR Video Reconstruction: A Coarse-to-fine Network and A Real-world Benchmark Dataset</p>
              <p class="authors">Guanying Chen, <span class="author_me">Chaofeng Chen</span>, Shi Guo, Zhetong Liang, K.-Y. K. Wong, Lei Zhang.</p>
              <p class="venue">International Conference on Computer Vision (ICCV), 2021</p>
              <a href="https://arxiv.org/abs/2103.14943" target="_blank"><img class="imgbadge arxivbadge"></a>
              <a href="https://github.com/guanyingc/DeepHDRVideo" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/guanyingc/DeepHDRVideo?style=social"></a>
              <a href="https://guanyingc.github.io/DeepHDRVideo/" target="_blank"><img class="prjbadge" src="https://img.shields.io/badge/project-HDRNet-e9f1f6?style=flat-square"></a>
            </td>
            </table>
          </div>

        <div class="hflex-container" id="paper">
          <table>
            <td class="imgtd">
            <img src="images/PSFR-GAN.jpg">
            </td>
            <td>
              <p class="title">Progressive Semantic-Aware Style Transformation for Blind Face Restoration</p>
              <p class="authors"><span class="author_me">Chaofeng Chen</span>, Xiaoming Li, Lingbo Yang, Xianhui Lin, Lei Zhang, K.-Y. K. Wong.</p>
              <p class="venue">Computer Vision and Pattern Recognition (CVPR), 2021</p> 
              <a href="https://arxiv.org/abs/2009.08709" target="_blank"><img class="imgbadge arxivbadge"></a>
              <a href="https://github.com/chaofengc/PSFRGAN" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/chaofengc/PSFRGAN?style=social"></a>
            </td>
            </table>
          </div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          		<img src="images/ECCV2020_dfdnet.jpg">
              </td>
              <td>
                <p class="title">Blind Face Restoration via Deep Multi-scale Component Dictionaries</p>
          		  <p class="authors">Xiaoming Li, <span class="author_me">Chaofeng Chen</span>, Shangchen Zhou, Xianhui Lin, Wangmeng Zuo, Lei Zhang</p>
                <p class="venue">European Conference on Computer Vision (ECCV), 2020</p> 
                <a href="https://arxiv.org/abs/2008.00418" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/csxmli2016/DFDNet" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/csxmli2016/DFDNet?style=social"></a>
              </td>
            </table>
        	</div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          		<img src="images/ACCV2018_face_sketch_wild.png">
              </td>
              <td>
                <p class="title">Semi-Supervised Learning for Face Sketch Synthesis in the Wild</p>
          		  <p class="authors"><span class="author_me">Chaofeng Chen</span>, Wei Liu, Xiao Tan, K.-Y. K. Wong.</p>
                <p class="venue">Asia Conference on Computer Vision (ACCV), 2018</p>
                <a href="https://arxiv.org/abs/1812.04929" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/chaofengc/Face-Sketch-Wild" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/chaofengc/Face-Sketch-Wild?style=social"></a>
              </td>
            </table>
        	</div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          	  <img src="images/ACCV2018_scale_aware_ocr.png">
              </td>
              <td>
         		   <p class="title">SAFE: Scale Aware Feature Encoder for Scene Text Recognition</p>
          		  <p class="authors">Wei Liu, <span class="author_me">Chaofeng Chen</span>, K.-Y. K. Wong.</p>
          		  <p class="venue">Asia Conference on Computer Vision (ACCV), 2018</p>
                <a href="https://arxiv.org/abs/1901.05770" target="_blank"><img class="imgbadge arxivbadge"></a>
              </td>
            </table>
        	</div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          		<img src="images/WACV2018_face_sketch_pcf.png">
              </td>
              <td>
         		    <p class="title">Face Sketch Synthesis with Style Transfer using Pyramid Column Feature.</p>
          		  <p class="authors"><span class="author_me">Chaofeng Chen<sup>*</sup></span>, Xiao Tan<sup>*</sup>, K.-Y. K. Wong. (<sup>*</sup> indicates equal contribution.)</p>
          		  <p class="venue">IEEE Winter Conference on Applications of Computer Vision (WACV), 2018</p> 
                <a href="https://arxiv.org/abs/2009.08679" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/chaofengc/Face-Sketch" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/chaofengc/Face-Sketch?style=social"></a>
              </td>
            </table>
        	</div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
        		  <img src="images/AAAI2018_char_net.png">
              </td>
              <td>
				         <p class="title">Char-Net: A Character-Aware Neural Network for Distorted Scene Text Recognition</p>
				         <p class="authors">Wei Liu, <span class="author_me">Chaofeng Chen</span>, K.-Y. K. Wong </p>
				         <p class="venue">AAAI Conference on Artificial Intelligence (AAAI), 2018 (<b style="color:red;">Oral Presentation</b>)</p> 
				         <a class="pdflink"><a href="http://www.visionlab.cs.hku.hk/publications/wliu_aaai18.pdf">PDF</a>
                 <a class="pptlink" href="http://www.visionlab.cs.hku.hk/publications/wliu_aaai18.pptx">PPT</a>
              </td>
            </table> 
			    </div>

          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
				      <img src="images/BMVC2016_star_net.png">
              </td>
              <td>
				         <p class="title">STAR-Net: A SpaTial Attention Residue Network for Scene Text Recognition.</p>
				         <p class="authors">Wei Liu, <span class="author_me">Chaofeng Chen</span>, K.-Y. K. Wong, Z. Su and J. Han</p>
				         <p class="venue">British Machine Vision Conference (BMVC), 2016</p>
				         <a class="pdflink" href="http://www.visionlab.cs.hku.hk/publications/wliu_bmvc16.pdf">PDF</a>
			        </td>
            </table>
          </div>
      <!-- </div> -->

    <!-------------------------------  Journals -------------------------------------------->
      <h3>Academic Journals</h3> 
          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          		<img src="images/TIP2020_SPARNet.png">
              </td>
              <td>
                <p class="title">Learning Spatial Attention for Face Super-Resolution</p>
          		  <p class="authors"><span class="author_me">Chaofeng Chen</span>, Dihong Gong, Hao Wang, Zhifeng Li, Kwan-Yee K. Wong</p>
                <p class="venue">IEEE Transactions on Image Processing (TIP), 2020</p>
                <a href="https://arxiv.org/abs/2012.01211" target="_blank"><img class="imgbadge arxivbadge"></a>
                <a href="https://github.com/chaofengc/Face-SPARNet" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/chaofengc/Face-SPARNet?style=social"></a>
              </td>
            </table>
        	</div>

    <!-------------------------------  Preprints -------------------------------------------->
      <h3>Preprints</h3> 
          <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          		<img src="images/TIP2021_FaceVideoInpaint.png">
              </td>
              <td>
                <p class="title">Deep Face Video Inpainting via UV Mapping</p>
          		  <p class="authors">Wenqi Yang, Zhenfang Chen, <span class="author_me">Chaofeng Chen</span>, Guanying Chen, Kwan-Yee K. Wong</p>
                <p class="venue">Arxiv Tech Report, 2021</p> 
                <a href="https://arxiv.org/abs/2109.00681" target="_blank"><img class="imgbadge arxivbadge"></a>
              </td>
            </table>
        	</div> 

    <!-------------------------------  Preprints -------------------------------------------->
      <h2>PhD Dissertation</h2>
         <div class="hflex-container" id="paper">
            <table>
              <td class="imgtd">
          	  <img src="images/Logo_HKU.jpg">
              </td>
              <td>
                <p class="title">Face Sketch Synthesis and Face Super Resolution in the Wild with Deep Learning</p>
          		<p class="authors"><span class="author_me">Chaofeng Chen</span></p>
                <p class="venue">Dept. of Computer Science, The University of Hong Kong, 2020</p>
                <a class="pdflink" href="https://hub.hku.hk/handle/10722/297490" target="_blank">HKU Theses Online</a>
              </td>
            </table>
         </div> 

    <!-------------------------------  Other information -------------------------------------------->
      <h2>Professional Activities</h2>
			<ul>
        <li><b>Conference Reviewer</b>:
          <ul>
            <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
            <li>International Conference on Computer Vision (ICCV)</li>
            <li>European Conference on Computer Vision (ECCV)</li>
            <li>Association for the Advancement of Artificial Intelligence (AAAI)</li>
            <li>ACM International Conference on Multimedia (ACM MM)</li>
          </ul>
        </li>
        <br>
				<li><b>Journal Reviewer</b>:
          <ul>
            <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
            <li>IEEE Transactions on Image Processing (TIP)</li>
            <li>IEEE Transactions on Multimedia (TMM)</li>
            <li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
            <li>Elsevier Journal of Neurocomputing (Neurocomputing)</li>
          </ul>
			</ul>

      <h2>Awards</h2>
			<ul>
        <li>Hong Kong PhD Fellowship, HKU, 2015 - 2018</li>
				<li>National Scholarship, HUST, 2011 - 2012</li>
			</ul>

		  <!-- <div class="content-container"> -->
			<h2>Teaching</h2>
			<ul>
       <!-- <li>[2017/18 2nd semester]: COMP3317 Computer Vision&nbsp;~ Teaching Assistant</li>
				<li>[2015/16 2nd semester]: COMP2396 Object-Oriented Programming and Java&nbsp;~ Teaching Assistant</li>
				<li>[2016/17 1st semester]: COMP2396 Object-Oriented Programming and Java&nbsp;~ Teaching Assistant</li>
			</ul>
--!>
			<h2>Other Links</h2>
			<table width="800">
				<tr>
					<td>
					    <ul>
					       	<li><a href="https://www.ustwumeng.com/" target="_blank">WU MENG</a></li>
					       
						</ul>
					</td>
					<td>
						<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.png?cl=ffffff&w=300&t=tt&d=v6gggiPA9L5DOHK3o65hlWcccvCPS-uBNnGjquGzyEw&co=2d78ad&ct=ffffff"></script>
					</td>
				</tr>
			</table>
		<!-- </div> -->
	</div>
</body>
</html>
